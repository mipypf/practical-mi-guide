{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mipypf/practical-mi-guide/blob/develop/chapter4/src/llm_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIcNd28499ZI"
   },
   "source": [
    "# RAGによるLLMへの知識付与"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ilmU2kPiNF1"
   },
   "source": [
    "### 右上の「接続」をクリックし、ランタイムに接続（ランタイムのタイプがT4 GPUになっていない場合、ランタイムのタブから「ランタイムのタイプを変更」→ハードウェアアクセラレータと進み、T4 GPUを選択）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9afWx_fKiQ3X"
   },
   "source": [
    "## ライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTCIbvzq3CKg",
    "outputId": "2ab8b2be-e9f7-4f7f-b963-f3f9f7385dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.20.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
      "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu124\n",
      "    Uninstalling torchvision-0.21.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.6.0+cu124\n",
      "    Uninstalling torchaudio-2.6.0+cu124:\n",
      "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# CUDA 12.4 のtorch 2.5.1をインストール（書籍執筆時のPytorchの環境）※最新のGoogle Colabの環境でエラーが出る場合は本セルは実行しないこと（ただし、書籍掲載の結果と多少の差分が発生し得る。）\n",
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiTT-Ql7_B-A",
    "outputId": "c76e7bc7-ecea-4f45-a828-3c1c22945df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.48.2\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentence-transformers==3.4.1 in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Collecting faiss-cpu==1.10.0\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting pypdf==4.1.0\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.2) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==3.4.1) (2.5.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==3.4.1) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==3.4.1) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==3.4.1) (11.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==3.4.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==3.4.1) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.2) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==3.4.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==3.4.1) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.4.1) (3.0.2)\n",
      "Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf, faiss-cpu, transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed faiss-cpu-1.10.0 pypdf-4.1.0 transformers-4.48.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.48.2 sentence-transformers==3.4.1 faiss-cpu==1.10.0 pypdf==4.1.0 #執筆当時のGoogle Colabの環境ではfaiss-gpuのpip installではERRORが発生するためCPU版をインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAE2JuSXickU"
   },
   "source": [
    "### 「ランタイム」タブから「セッションを再起動する」を選択し、「はい」をクリック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oB-SqzT-QzY",
    "outputId": "8060533b-184e-4a50-ccdd-3b419d00f445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  8 08:50:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 以下のコマンドでGPUが使用可能かを確認\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロード\n",
    " - https://github.com/mipypf/practical-mi-guide/tree/main/chapter4/input から MIハンドブック_はじめに.pdfをダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9ZV5dG0-c9B"
   },
   "source": [
    "## Google Colabの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TFVmb2LO-f9F"
   },
   "outputs": [],
   "source": [
    "# Google Colabを利用する場合はTrue、そうでない場合はFalseとする\n",
    "colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5FCROZ1g-gEM"
   },
   "outputs": [],
   "source": [
    "# Google Colabのファイルをクリックし、MIハンドブック_はじめに.pdfをドラッグ＆ドロップしてアップロード\n",
    "if colab:\n",
    "  INPUT_FILE_PATH = \"./\"\n",
    "  OUTPUT_FILE_PATH = \"./\"\n",
    "else:\n",
    "  INPUT_FILE_PATH = \"../input/\"\n",
    "  OUTPUT_FILE_PATH = \"../output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOEfCbBo99ZL"
   },
   "source": [
    "## ライブラリをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L1O5bIVk99ZL"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Markdown\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQDxVSVi99ZM"
   },
   "source": [
    "## データを読み込み文章を一定のまとまり（チャンク）に分割し、前処理を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZTBbx6kp99ZM"
   },
   "outputs": [],
   "source": [
    "# PDFを読み込む関数\n",
    "def load_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# テキストをチャンクに分割する関数\n",
    "def split_text(text, chunk_size=400):\n",
    "    chunks = [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# PDFから抽出したテキストから改行コードを削除する関数\n",
    "def clean_text(text):\n",
    "    return text.replace(\"\\n\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3vKXQ6ld99ZM"
   },
   "outputs": [],
   "source": [
    "# PDFファイルをロードしてチャンクに分割\n",
    "file_path = INPUT_FILE_PATH + \"MIハンドブック_はじめに.pdf\"\n",
    "text = load_pdf(file_path)\n",
    "cleaned_text = clean_text(text)\n",
    "documents = split_text(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHOopoCE99ZM",
    "outputId": "21a22baf-0edf-49b4-cb01-36533e1a370a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['はじめに   良い材料を早くつくりたいので、 マテリアルズ・インフォマティクス（MI）を活用して”いる”。このような 声はもう珍しくありません。   MIブームに端を発して、大学・企業 ともにMIの活用検討 が始められて 既にある程度の期間が経過しました。すでに MIに取り組んでいる 大学・企業 からはMI活用の成果が多く報告されており、 MIは期待に応えられるということが共通理解 になりつつあります。 MIとは？有効なものなのか？が 大勢を占めていた 数年前とは隔世の感があります。   本書を手に取っていただいた 方は、材料開発者 として、あるいは 材料開発を支援するデータ分析者として「 MI を活用して材料開発 を加速したい。 」という気持ちだと考えています。      著者の高原と福岡は多くの民間企業 などに対して MI 活用の支援をさせて頂いています。 学生時代 には二人とも材料工',\n",
       " '学 を専攻し、それぞれ 別メーカーでMIを活用した材料開発業務 を経て、現在はコンサルティング・データ 分析・講演・教育・ データ活用システム の提供といった 様々な立場・内容 で活動を行っています。    MIの普及に伴い、様々な書籍やセミナー が発刊・実施 されています。しかしそれは、 MIとは？という 概論か、整形されたデータに対して分析アルゴリズムを適用するものが 主と感じています。   材料開発 の実務の中で MI を活用するには、さらに 踏み込んだ情報が必要です。  例えば、データの整形方法。 MIに限らず機械学習・ データ分析の入門書では分析可能 な形に整形されたデータから分析がスタート します。 一方で、MI が普及していない 材料開発 の現場では、データ分析フレンドリー な形でデータが蓄積されていません。そのため、その データを分析可能 にする手順が分からずMIの活用を断',\n",
       " '念してしまうことがあります。   次にデータや分析結果 の見方という観点。本書執筆 の時点では、AIにデータを丸ごと投げ込み、出てきた結果をそのまま 実験すればより 良い材料が出来るということは、ほとんどの 場合ありません。 手持ちのデータのどのような点に着目し、データ分析を適用するか。 出てきた分析結果 をどのように 材料開発の加速に役立てていくか。こういった ノウハウ が必要になります。    著者らは、様々な材料系（有機材料、無機材料、 コンポジット 材料、 ・・・  etc） ・データ 形式（テーブルデータ、 画像データ、テキストデータ、材料構造 データ、 ・・・ etc）を扱うMIプロジェクト の実施経験 の中で、開発する材料を問わず共通的に有用なノウハウ を蓄積してきました。 本書籍では、その 内容をお伝えできればと 思います。      本書では、MIとは？からはじまり、 材',\n",
       " '料開発 の実務でよくある 未整形のデータから分析するまでの 流れと、分析結果 の材料開発 への役立て方、そして読者の方が今後さらに分析力を向上させるための 指針を示します。   こうした 内容をまとめ、 材料開発 の中で MI を活用するときのお 供となることを目指して、本書を “ハンドブック ”と名付けています。   MIの知識ゼロから自分の材料開発 データに適用できるように MIの力を身につけてほしいと 考えています。     【本書の対象読者】   本書は、次のような 読者を対象にしています。     ・これから MIとは何かを学びたい人  ・機械学習 やMIに入門してみたが、 実際に自分の材料開発 に適用できておらず悩んでいる 人    このような 読者が、MIの知識ゼロから自分の材料開発 データに適用できるようになり、 入門以後 のスキルアップ の道筋に目星がつくようになるまでを',\n",
       " ' 目指しています。ただし、 本書はプログラミング の入門書ではないため、 コードを書籍の中で丁寧に追って解説することはしません。また、 機械学習 アルゴリズム 等の数式についてもほとんど 触れません。 プログラミング が分からずとも、 数学が苦手でも MI とはなにか？ 何をしているのかの 雰囲気がつかめることを 優先しているためです。 本書で示す分析例を実行できる分析コードとしてPythonで作成したものを GitHub上に公開しています。 コード中に補足解説 も行っているため、 興味がある方は次のリンクにアクセス して内容を確認して下さい。ただし、 Github上では、コードを動作させることができないため、 入出力の確認のみとなります。   コードを実際に動かしてみたい 方は GitHub 上に公開している リンクから Google Colab にアクセス いただき Google Co',\n",
       " 'lab 上で動作を試みてください。また、Github上では、コードの出力結果 が一部確認 できません。こちらの コードについても Google Colab で内容を確認してください。 Google Colab の使い方はGitHub上に記載しています。      GitHub Link: https://github.com/mipypf/practical -mi-guide']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxRqyC4x99ZN"
   },
   "source": [
    "## Transformer系列のモデルを用いたベクトル化を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "8a7b7de896ac45809c3df68ffd52da28",
      "b58bbec9d14b4dd0ab43e3fedba98702",
      "a95d28fca24848a5ac9b70f9755a1cd0",
      "192d8e98743843f7b738a28fb7faad29",
      "39779676f00247e9a3f29ec99b2883a0",
      "5d6f302494134a36a6b0c88f696d4db6",
      "dbdb140291a14b099a1f54bb1425278c",
      "e0c4b6c36176409a8d3d74087d244d52",
      "7c151fc4cedb4adf8072642d25f160c7",
      "29af88da50ea41b7bd3b0243c933188d",
      "7585d1e98777487f92b2f99fde928218",
      "af89ab46bc7c4a9497d788d58bee510c",
      "527c5530c09e492894f0f8e2343f99af",
      "fcaba9bda7cc464c890c2d3bf3417fc8",
      "a6a5a4807cb74dcca117e1d53525fe8a",
      "d54d311bec32463c84b5ea23bfd81329",
      "79256591609e4833bccaaf1b53f673c1",
      "9168399960fb4f66b83094aea865ea73",
      "261e1fc41c704de8a41bc6fcaf9e3741",
      "78f92ba3110c4aef872b130bda80be5b",
      "8463c58418ff492996fe5418acd14f56",
      "37d88f71527a4a5087316af195139627",
      "b51ed1a7f38946a6ad8431953fe7ca03",
      "4a107fad309e4dbcab46dd42f5a82624",
      "8ff30f3019354b18b894ef696c3ae3e6",
      "56b0dc8dbad740df8f0872728785ba8e",
      "f850fbff41154f1abffa59ebe5b71795",
      "f967f33462634fb7a688983c9e25025a",
      "113811d5f39a4353855d16dbaddb3785",
      "a3bc7825a3894c2a83e36613ead5aaef",
      "509c62115bd8420cb452e985fca1d5a7",
      "d114ee3c4d8a4f2784ec290fbef1e12b",
      "72736f2875684d2e89d7e96493d6e45f",
      "592a2a21638246fa8f3043c8dc5f4ee5",
      "05953404fdea4d4c9dd00cf9f2f49d97",
      "ef82d1184a484a678d9eb65f33c27f09",
      "05260f106a56411c85ed29e0de65e948",
      "e232a4d16fe44d9b8e119fc6904dcab6",
      "493d585384984a269de382819f1e891f",
      "35aae8a431b0477295b32d95334ce9d6",
      "ef3a840d5b8c4255acf9e51dc05d198f",
      "570177fecfda484e8c287e50385e773f",
      "a97a5ecad358409caee5787a53d1e0e0",
      "db962ef57d344f05873ee9d2aeba3467",
      "9a293c8d5a764cb4be4f557a65419b32",
      "a517596e60b84125b5180b970eec89b4",
      "fbbdde282bb441cf97c0a7e06fd3e277",
      "9b797143d5214f2eb58a24d267f4a4b1",
      "d5bfe28dcfeb4d4789451b44f62c0a5b",
      "b366804e56a8494aa3736f659625531b",
      "61f9323b7b8c4411af48679954e792cc",
      "b76d956c6d0d47408f2bf8bfa530ee54",
      "0924ddbbb4d8488c84e11b3150a3dd99",
      "9fcc9e66f53b40d5afc8606208311e1d",
      "e2c4224e8acb481aa455ce700f22c0f8"
     ]
    },
    "id": "XwROdz7e99ZN",
    "outputId": "f0fa68a4-f73c-4cd6-8ba8-14e351c33dc7"
   },
   "outputs": [],
   "source": [
    "# SentenceTransformerを使用して埋め込みを生成\n",
    "embedding_model = SentenceTransformer(\"hotchpotch/static-embedding-japanese\")\n",
    "embeddings = embedding_model.encode(documents, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Z-mcibO99ZN",
    "outputId": "bb3a9a65-ce48-42b4-c8d3-e29d01f7490a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05173758,  0.6336742 , -0.04424471, ...,  0.41521037,\n",
       "         0.43883392, -0.05663063],\n",
       "       [ 0.16895677,  0.57790726,  0.10041223, ...,  0.40658203,\n",
       "         0.17393637, -0.08954899],\n",
       "       [ 0.10091873,  0.92745125,  0.10893159, ...,  0.14876802,\n",
       "         0.12086256,  0.2714417 ],\n",
       "       [ 0.01127777,  0.6932841 , -0.19651257, ...,  0.5039406 ,\n",
       "         0.7157471 , -0.07765815],\n",
       "       [ 0.19314238,  1.0728737 , -0.23075989, ...,  0.21142139,\n",
       "         0.14913718,  0.08873185],\n",
       "       [ 0.38439566,  1.1642637 , -0.44445807, ...,  0.3353256 ,\n",
       "        -0.4096954 , -0.0997018 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QKkCXXj99ZN"
   },
   "source": [
    "## 検索ができるようにベクトル化したテキストデータにインデックスを付与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eSbhXEph99ZO"
   },
   "outputs": [],
   "source": [
    "# FAISSインデックスを作成\n",
    "d = embeddings[0].shape[0]  # 埋め込みの次元\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLK95uFR99ZO"
   },
   "source": [
    "## LLMを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOEa9r9ZDGOP"
   },
   "source": [
    "### HuggingFaceでの作業\n",
    " - https://huggingface.co/google/gemma-2-2b-jpn-it にアクセスしてログインし、ライセンス認証を行う。（Sign up未の場合は、登録から行う。）\n",
    " - HuggingFaceのトークンをhttps://huggingface.co/settings/tokens から取得\n",
    " - Google Colabのシークレット（鍵マークのアイコン）をクリックして開き、「+ 新しいシークレットを追加」からHF_TOKENという名前を付けて、値の欄に取得したトークンを入力\n",
    " - ノートブックからのアクセスを有効にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rAGlNsMTFrIX"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=userdata.get('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "25609cc38c7d4c19adb26d607ead0a60",
      "d9853f3a3d9b49f88b235145533f526c",
      "c866d38424be4f48ae81806f4ef08d38",
      "9b4260791da44631a83aff6d19b350cb",
      "dc8779e0f188411e8ab6f5e7e4136459",
      "a328a8ad1c5746a38ba552e158ba324d",
      "fa6dcba9edc84a47809cc528ce0f67ab",
      "27d79d73ee0146818234bc0f545ee4f0",
      "52b7f293cf7040a986f4e5f37348b0f3",
      "5ce4719d566f40788dbb5c0c7ef7c126",
      "287a7842e3904d658b17ed4722694015",
      "5889b89f257f4ea39f9259336b79522c",
      "0feaed0784c94b82b6e948c14fa9e621",
      "dd24ec7ed6354654ac307b6e7d038a4b",
      "e7199ec3109c4537b84e30696b7e56f6",
      "aaaa995d88804326be4c7468b79366de",
      "882f0d6d8f904bb0a6b88d0f5a20d574",
      "035c139ad45f43098fca65b17e97bd6e",
      "2a50cfaafd3a4775bbe3d1d9df5983d4",
      "d9be094ced1b4532aafd450e51cd0b0e",
      "e69e3b29503f4ac88d857a1b401d3349",
      "a931999bb37649328259294c9217aa58",
      "f09c51ee51134e898942f26349bfccdc",
      "328ff7a94882464d8a12a780a0d3a400",
      "612c42d8252f4eefab3657626af9cad5",
      "d241bcee6fd745ccba1ce1c3e483ded2",
      "36cc2556283448a698d913b352cc34a0",
      "3a8131c051ac46c4b5ac18bf24a27f76",
      "40b98d8d911b4479bfd3c50ff01d6f77",
      "33815839c71d41e6b91f196176684eed",
      "22bbf8b0a3d044c49eb20404264e81c6",
      "b6c11c43e6274fc8aca4e62e4c9841a5",
      "3dff6c5dbc6c4f6c997ef481a54e6820",
      "6cb26cd1d17546908e50fcc592f609ba",
      "c055771fc65a46afa08507508f711dea",
      "3e6ce1f09f43409fbc919ec4bdc6c2b2",
      "def29f1ae73c4ccc9665b6a1bd3badee",
      "061c643fce2c44e889a3a1d95c1b67f4",
      "04ff5c8c59774ca59be480b9a0101936",
      "b20150bc540a4358a56a5e6d2746585e",
      "2ed414ef8ae44fe5b532406270e0418b",
      "88aa4ac10b184ba5bd7eead8ada5e5a3",
      "1c8cd1d13ade4b24a29521bc098e4c46",
      "fe770c8e4da442f99cb595c97d0c9508",
      "188d17da995c4f08a64221c87701d36d",
      "849498e056bc45fe88987e8627ebddbb",
      "524508d322c44c5ab8d8a23e5fd9edcf",
      "5453272ed7824ee4910bb8070b310877",
      "e5666f9d138147a2b9dd5e2ddba657db",
      "16aae8dd018b400c86867b2ceed317c0",
      "20c5e88fd8f44b7d8965be25353c10cd",
      "6a26b0b8b37c4ba98e8c515e184d4457",
      "bdbdd5f7c0a94064905d95cade104771",
      "b8adb327db3b450aab3868a82cd0fb55",
      "41575ef5411246e1872500473630a8f5",
      "9ccb0718af694954be7ccd543771bfd8",
      "86e25fbd59314e8f909656ef873b682f",
      "6f81e107212549b0b371902acb1e5aaf",
      "4972ecb20ba0476bafe2660479f5cad7",
      "6be8f2e2630c483c85b1340c5c20a092",
      "65cdd000dfbb46b2ab8bd7b249f238e3",
      "8ae74af35fac4017942d050ec0bcd7a0",
      "5d79d29ac97c4c268bc538f3416ae018",
      "c7a654963b0946f2b605784d45af2362",
      "1438586d3ec241c2a4c548691bc9b1dd",
      "7b18b6f41bb649c49cd28d8f6c080418",
      "9cc0ec65ae384acfb4cf9e9ad1afd802",
      "5c453b31ead44dbc85bce2b206c8bb89",
      "29811e3ace344037ab04ca968e51ac16",
      "907f165c13044b568bac9e5e18278bc4",
      "bf1493d8d97c48e5af9df473027ab580",
      "c18b607b3bce43759df7f166c1e4a7a8",
      "7c4c6ba36c5f4a8ca4fc989c68d5f35a",
      "43539b3744c240fca68b736a7f370ab4",
      "1e860e72e020440fbcfe4ff1228a1c34",
      "b0bf231a12d345578232ac08ff3101ac",
      "1d7c3f81a7d24de3848b2ac9e23390c6",
      "90a4ad986a834a3aaf46b20006888c52",
      "eb36dcb0c56642b99169ff25f8400785",
      "ca8b22af75134ce7a54ac09175244ae6",
      "d7e1d2d4bd57425fb4d16b6bca8fda19",
      "5e525a1b0f0b4fe4a70352589a3cd17e",
      "0fcca6e677ff41dd8b0bcb11309e9032",
      "ebf2842c36734ce5a44f369892a5d3f9",
      "98a033a7bafb439d8b34e2535e6ef25c",
      "e5dc9a8646b14a00a13337bd66707aa4",
      "439b9101f690468d96945f144fdc15bd",
      "ee54a614f8644c3f8978778962b9cff0",
      "8afca402996547b5a9fdade16e9739ac",
      "399309ea1bd84cf4b9429072aac10df6",
      "69bc8f3c550c4886ae2c11453cee4cb3",
      "d502627faab148b78071dbe1168359dd",
      "63141c8e1a7f48dab579df07836da7c1",
      "ba3ffe66e02c47e4b1b58c8b5a570978",
      "0a4f056a9ecd4efb92ab168a481b9cbe",
      "40601fb88ac64c4882029337d00c9f82",
      "a7ca3d5256514065a6c26de231a14b02",
      "e762b30e03b34685b63019363513d884",
      "457ecbc78abe482ebfc900df3b714806",
      "d6f75c3ee02c4a9c840f4a7e6aaa4177",
      "c9d7afac910541f9a41d594e46d072bc",
      "869bdba8c0334023b5695271b6f662ca",
      "e109e178fb8f406488ed11813dabf9f9",
      "1d67c3f7720147e2b63083ed3f6aa9e5",
      "2be3843c58c447a798a744b6594c79e3",
      "7e99aacfee944182bf6598bda6b837d5",
      "27e85e0d02f1434e9288f7b142dcda3d",
      "83e12a4b3e9f463982032011061b5095",
      "504080ba03f646218ddf4b8d17601ad5",
      "0f079924199c4e73ae3eb19997b41ba7",
      "242e9f4ca14f45c6b098ff34939711df",
      "b0bd0e07694c4a11bc14a698aad54100",
      "c4141c2119ec4b4aaf17f047b4d95edd",
      "25e692e723774165af5cf05bdc9af5dd",
      "ab16f25377de492b93c54be9e564d570",
      "7094b4c5c7de435f85a1a33943a6a45c",
      "e87cf80b1251438ca23e8f7922e5c9c1",
      "984eccc0cf9843fea468a90285395626",
      "548e2c41336e4d2895d0cccbbce85168",
      "2f0a8c507e1f4d3e803a08ccceec9189",
      "82ff308cc4c24674ac6f7ccaea125b3c"
     ]
    },
    "id": "gaDkRy_f99ZO",
    "outputId": "80fbd650-ed17-4e71-84a1-9d22af6abbb5"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-jpn-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-jpn-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naMU6-uZ99ZO"
   },
   "source": [
    "## テキスト生成のための設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Of_oUkK99ZO",
    "outputId": "fab1b0f9-86fb-4490-ff37-b33f6680f5c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# テキスト生成パイプラインを設定\n",
    "text_gen_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "L2-OCOsw99ZO"
   },
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # 質問を埋め込みに変換\n",
    "    question_embedding = embedding_model.encode([question], convert_to_tensor=False)\n",
    "\n",
    "    # FAISSで最も近いチャンクを検索\n",
    "    _, indices = index.search(np.array(question_embedding), k=1)\n",
    "    retrieved_text = documents[indices[0][0]]\n",
    "\n",
    "    # 質問と関連情報、回答の間に改行を追加\n",
    "    input_text = f\"質問: {question}\\n\\n関連情報: {retrieved_text}\\n\\n回答: \"\n",
    "\n",
    "    # パイプラインを使用して回答を生成\n",
    "    outputs = text_gen_pipeline(input_text, max_new_tokens=256)\n",
    "\n",
    "    # リストから文字列を取得\n",
    "    assistant_response = outputs[0][\"generated_text\"].strip()\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNiozQ7I99ZO"
   },
   "source": [
    "## RAGを使用せず知識付与を行わない状態でLLMに質問する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5Hv5mVB99ZO",
    "outputId": "3589066f-2661-4cc6-e45d-b8b8542204bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIとは何ですか？\n",
      "\n",
      "「**AI**」の略称で、人工知能の技術です。\n",
      "\n",
      "**AIとは？**\n",
      "\n",
      "* **人間のような思考・判断能力を持つコンピュータ**\n",
      "* **学習・分析・予測・行動**を自動化できる能力を持つ\n",
      "\n",
      "**AIの活用例**\n",
      "\n",
      "* **自動運転車**\n",
      "* **医療診断**\n",
      "* **顧客対応**\n",
      "* **商品推薦**\n",
      "* **翻訳**\n",
      "* **画像認識**\n"
     ]
    }
   ],
   "source": [
    "question = \"MIとは何ですか？\"\n",
    "\n",
    "outputs = text_gen_pipeline(question, max_new_tokens=256)\n",
    "response = outputs[0][\"generated_text\"].strip()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "AhYK7p3Z99ZO",
    "outputId": "17f83c8e-063e-4fd9-d49d-c459ab0bb424"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MIとは何ですか？\n",
       "\n",
       "「**AI**」の略称で、人工知能の技術です。\n",
       "\n",
       "**AIとは？**\n",
       "\n",
       "* **人間のような思考・判断能力を持つコンピュータ**\n",
       "* **学習・分析・予測・行動**を自動化できる能力を持つ\n",
       "\n",
       "**AIの活用例**\n",
       "\n",
       "* **自動運転車**\n",
       "* **医療診断**\n",
       "* **顧客対応**\n",
       "* **商品推薦**\n",
       "* **翻訳**\n",
       "* **画像認識**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdJbQTBz99ZO"
   },
   "source": [
    "## RAGを使用して知識付与を行った状態でLLMに質問する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi3G1CyN99ZP",
    "outputId": "8975c051-3854-4fdd-d1f7-2a4a8ca7d625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問: MIとは何ですか？\n",
      "\n",
      "関連情報: はじめに   良い材料を早くつくりたいので、 マテリアルズ・インフォマティクス（MI）を活用して”いる”。このような 声はもう珍しくありません。   MIブームに端を発して、大学・企業 ともにMIの活用検討 が始められて 既にある程度の期間が経過しました。すでに MIに取り組んでいる 大学・企業 からはMI活用の成果が多く報告されており、 MIは期待に応えられるということが共通理解 になりつつあります。 MIとは？有効なものなのか？が 大勢を占めていた 数年前とは隔世の感があります。   本書を手に取っていただいた 方は、材料開発者 として、あるいは 材料開発を支援するデータ分析者として「 MI を活用して材料開発 を加速したい。 」という気持ちだと考えています。      著者の高原と福岡は多くの民間企業 などに対して MI 活用の支援をさせて頂いています。 学生時代 には二人とも材料工\n",
      "\n",
      "回答: \n",
      "\n",
      "MI（Materials Informatics）とは、材料の特性や性能を分析し、設計・開発を効率化するための、材料科学とデータ分析の融合技術です。\n",
      "\n",
      "\n",
      "**簡単に言うと:**\n",
      "\n",
      "* 材料のデータを集めて分析し、より良い材料の開発を支援する技術です。\n",
      "* 材料の特性や性能を数値化し、設計段階で最適な材料を選択できるようになります。\n",
      "\n",
      "\n",
      "**MIのメリット:**\n",
      "\n",
      "* **材料開発のスピードアップ:**  大量のデータから、最適な材料を見つけることができます。\n",
      "* **コスト削減:**  設計段階で失敗を減らし、無駄な材料や工程を削減できます。\n",
      "* **材料の性能向上:**  データ分析によって、材料の性能を向上させるための設計が可能になります。\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "V9wrYs9T99ZP",
    "outputId": "77da6636-c9c8-4fcd-dcd3-5cef0e37b90e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "質問: MIとは何ですか？\n",
       "\n",
       "関連情報: はじめに   良い材料を早くつくりたいので、 マテリアルズ・インフォマティクス（MI）を活用して”いる”。このような 声はもう珍しくありません。   MIブームに端を発して、大学・企業 ともにMIの活用検討 が始められて 既にある程度の期間が経過しました。すでに MIに取り組んでいる 大学・企業 からはMI活用の成果が多く報告されており、 MIは期待に応えられるということが共通理解 になりつつあります。 MIとは？有効なものなのか？が 大勢を占めていた 数年前とは隔世の感があります。   本書を手に取っていただいた 方は、材料開発者 として、あるいは 材料開発を支援するデータ分析者として「 MI を活用して材料開発 を加速したい。 」という気持ちだと考えています。      著者の高原と福岡は多くの民間企業 などに対して MI 活用の支援をさせて頂いています。 学生時代 には二人とも材料工\n",
       "\n",
       "回答: \n",
       "\n",
       "MI（Materials Informatics）とは、材料の特性や性能を分析し、設計・開発を効率化するための、材料科学とデータ分析の融合技術です。\n",
       "\n",
       "\n",
       "**簡単に言うと:**\n",
       "\n",
       "* 材料のデータを集めて分析し、より良い材料の開発を支援する技術です。\n",
       "* 材料の特性や性能を数値化し、設計段階で最適な材料を選択できるようになります。\n",
       "\n",
       "\n",
       "**MIのメリット:**\n",
       "\n",
       "* **材料開発のスピードアップ:**  大量のデータから、最適な材料を見つけることができます。\n",
       "* **コスト削減:**  設計段階で失敗を減らし、無駄な材料や工程を削減できます。\n",
       "* **材料の性能向上:**  データ分析によって、材料の性能を向上させるための設計が可能になります。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(ask_question(question)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPeZZZvhH9wq"
   },
   "source": [
    "## 実行環境のライブラリverを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lgIHpjPhHH52"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements_llm_rag.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "FdN6lJVJHUJ2",
    "outputId": "4d79e9de-dd8a-43fc-b1ae-f479fc680bdd"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_61511e67-1bb8-4fea-b98f-bd798330a84b\", \"requirements_llm_rag.txt\", 12263)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('requirements_llm_rag.txt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
