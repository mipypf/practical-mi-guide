{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGによるLLMへの知識付与"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Markdown\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを読み込み文章を一定のまとまり（チャンク）に分割し、前処理を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFを読み込む関数\n",
    "def load_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# テキストをチャンクに分割する関数\n",
    "def split_text(text, chunk_size=300):\n",
    "    chunks = [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# PDFから抽出したテキストから改行コードを削除する関数\n",
    "def clean_text(text):\n",
    "    return text.replace(\"\\n\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFファイルをロードしてチャンクに分割\n",
    "file_path = \"../input/MIハンドブック_はじめに.pdf\"\n",
    "text = load_pdf(file_path)\n",
    "cleaned_text = clean_text(text)\n",
    "documents = split_text(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['はじめに   良い材料を 早く創りたいので 、マテリアルズ・インフォマティクス（ MI）を活用して”いる”。このような声 はもう珍しくありません 。 MIブームに端を発して 、大学・企業 ともにMIの活用検討が 始められて 既にある程度の期間が 経過しました 。すでにMIに取り組んでいる 大学・企業 からはMI活用の成果 が多く報告されており 、MIは期待に応えられるということが共通理解になりつつあります。 MIとは？有効なものなのか？が大勢を占めていた数年前とは隔世の感があります。  本書を手に取っていただいた方は、 材料開発者として、 あるいは材料開発を支援する データ分析者として「MIを',\n",
       " '活用して 材料開発を加速したい。 」という気持ち だと考えています 。   著者の高原と福岡は 多くの民間企業などに対して MI活用の支援をさせて頂いています。 学生時代に は二人とも 材料工学を専攻 し、それぞれ別 メーカーでMIを活用した材料開発業務を経て、 現在はコンサルティング ・データ分析・講演・教育・データ活用システムの提供 といった 様々な立場 ・内容で活動を行って います。  MIの普及に伴い、様々な書籍やセミナーが 発刊・実施されています 。しかしそれは、MIとは？という概論か、 整形されたデータに対して分析アルゴリズムを適用する ものが主と感じています。  材料開発の実務の',\n",
       " '中で MIを活用するには、さらに踏み込んだ情報が必要です。 例えば、データの整形方法。 MIに限らず機械学習 ・データ分析の入門書では分析可能 な形に整形されたデータから分析がスタートします。一方で、 MIが普及していない 材料開発の現場では、 データ分析フレンドリーな 形でデータが蓄積されていません。そのため、そ のデータを分析可能にする手順が分からずMIの活用を断念してしまうことがあります 。 次にデータや分析結果の 見方という観点。 本書執筆の 時点では 、AIにデータを丸ごと投げ込み、出てきた結果をそのまま実験すればより良い材料が出来るということは 、ほとんどの場合 ありません 。手持',\n",
       " 'ちのデータのどのような点に着目し、 データ分析を適用するか。出てきた分析結果を どのように 材料開発の加速に役立て ていくか。こういった ノウハウが必要に なります。  著者らは、様々な材料系（有機材料、無機材料、コンポジット材料、 ・・・etc） ・データ形式（テーブルデータ、画像データ、テキストデータ、材料構造データ、 ・・・ etc）を扱うMIプロジェクトの 実施経験の中で 、開発する材料を問わず 共通的に 有用なノウハウを蓄積してきました 。本書籍では、その内容をお伝えできればと思 います。    本書では、 MIとは？からはじまり 、材料開発の 実務でよくある 未整形の データから分',\n",
       " '析するまでの流れと 、分析結果の材料開発 への役立て方 、そして読者の方が今後さらに分析力を向上させるための 指針を示します 。 こうした内容を まとめ、 材料開発の中で MIを活用するときの お供となることを目指して、 本書を “ハンドブック”と名付け ています 。 MIの知識ゼロから 自分の材料開発 データに適用できる ようにMIの力を身につけてほしい と考えています 。  【本書の対象読者】  本書は、 次のような読者を対象にしてい ます。  ・これから MIとは何か を学びたい人  ・機械学習や MIに入門してみたが、 実際に自分の材料開発に 適用できておらず悩んでいる人   このよう',\n",
       " 'な読者が、 MIの知識ゼロから自分の材料開発データに適用できるようになり、入門以後のスキルアップの道筋に目星がつくようになるまでを目指しています。ただし、 本書はプログラミングの入門書ではないため、 コードを書籍の中で 丁寧に追って解説することはし ません。また、機械学習アルゴリズム等の数式についてもほとんど触 れません 。プログラミングが分からずとも、数学が苦手でも MIとはなにか？何をしているのか の雰囲気がつかめることを優先しているためで す。本書で示す分析例を実行できる 分析コードとしてPythonで作成したもの をGitHub上に公開してい ます。コード中に補足解説も行っているため、',\n",
       " ' 興味がある方は 次のリンク にアクセスして内容を確認して 下さい。ただし、 Github上では、コードを 動作させることができないため、入出力の確認のみとなります。  コードを実際に動かして みたい方は GitHub上に公開している リンクからGoogle Colab にアクセスいただき Google Colab 上で動作を試みてください。また、Github上では、コードの出力結果が一部確認でき ません。こちらのコードについても Google Colab で内容を確認してください。 Google Colab の使い方は GitHub上に記載しています。    GitHub Link:  ht',\n",
       " 'tps://github.com/mipypf/practical -mi-guide']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer系列のモデルを用いたベクトル化を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d40648f46441c8a78562c94eb4c749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SentenceTransformerを使用して埋め込みを生成\n",
    "embedding_model = SentenceTransformer(\"tohoku-nlp/bert-base-japanese-char\")\n",
    "embeddings = embedding_model.encode(documents, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00860138, -0.01544509,  0.05732762, ...,  0.10766538,\n",
       "         0.02744278,  0.07329488],\n",
       "       [-0.02874077, -0.03830459,  0.0481893 , ...,  0.10121736,\n",
       "         0.02751632,  0.04565822],\n",
       "       [-0.00059892, -0.09614192,  0.06609966, ...,  0.07873933,\n",
       "        -0.14247668,  0.16064684],\n",
       "       ...,\n",
       "       [ 0.05802056, -0.14048971,  0.08772241, ...,  0.11404857,\n",
       "        -0.02176722,  0.12419258],\n",
       "       [ 0.050071  , -0.04091918, -0.02482079, ...,  0.0119293 ,\n",
       "         0.0106582 ,  0.05920728],\n",
       "       [ 0.02757211,  0.03278049,  0.03972042, ...,  0.04832372,\n",
       "         0.0965587 , -0.30393988]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検索ができるようにベクトル化したテキストデータにインデックスを付与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISSインデックスを作成\n",
    "d = embeddings[0].shape[0]  # 埋め込みの次元\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26977eacd3640c48cf0815a54f9257d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-jpn-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-jpn-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキスト生成のための設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト生成パイプラインを設定\n",
    "text_gen_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # 質問を埋め込みに変換\n",
    "    question_embedding = embedding_model.encode([question], convert_to_tensor=False)\n",
    "\n",
    "    # FAISSで最も近いチャンクを検索\n",
    "    _, indices = index.search(np.array(question_embedding), k=1)\n",
    "    retrieved_text = documents[indices[0][0]]\n",
    "\n",
    "    # 質問と関連情報、回答の間に改行を追加\n",
    "    input_text = f\"質問: {question}\\n\\n関連情報: {retrieved_text}\\n\\n回答: \"\n",
    "\n",
    "    # パイプラインを使用して回答を生成\n",
    "    outputs = text_gen_pipeline(input_text, max_new_tokens=256)\n",
    "\n",
    "    # リストから文字列を取得\n",
    "    assistant_response = outputs[0][\"generated_text\"].strip()\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGを使用せず知識付与を行わない状態でLLMに質問する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIとは何ですか？\n",
      "\n",
      "「**AI**」の略称で、人工知能の技術です。\n",
      "\n",
      "**AIとは？**\n",
      "\n",
      "* **人間のような思考・判断能力を持つコンピュータ**\n",
      "* **学習・分析・予測・行動**を自動化できる能力を持つ\n",
      "\n",
      "**AIの活用例**\n",
      "\n",
      "* **自動運転車**\n",
      "* **医療診断**\n",
      "* **顧客対応**\n",
      "* **商品推薦**\n",
      "* **翻訳**\n",
      "* **画像認識**\n"
     ]
    }
   ],
   "source": [
    "question = \"MIとは何ですか？\"\n",
    "\n",
    "outputs = text_gen_pipeline(question, max_new_tokens=256)\n",
    "response = outputs[0][\"generated_text\"].strip()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MIとは何ですか？\n",
       "\n",
       "「**AI**」の略称で、人工知能の技術です。\n",
       "\n",
       "**AIとは？**\n",
       "\n",
       "* **人間のような思考・判断能力を持つコンピュータ**\n",
       "* **学習・分析・予測・行動**を自動化できる能力を持つ\n",
       "\n",
       "**AIの活用例**\n",
       "\n",
       "* **自動運転車**\n",
       "* **医療診断**\n",
       "* **顧客対応**\n",
       "* **商品推薦**\n",
       "* **翻訳**\n",
       "* **画像認識**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGを使用して知識付与を行った状態でLLMに質問する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f553f28c84d95b2a8f4c090ca41f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問: MIとは何ですか？\n",
      "\n",
      "関連情報: はじめに   良い材料を 早く創りたいので 、マテリアルズ・インフォマティクス（ MI）を活用して”いる”。このような声 はもう珍しくありません 。 MIブームに端を発して 、大学・企業 ともにMIの活用検討が 始められて 既にある程度の期間が 経過しました 。すでにMIに取り組んでいる 大学・企業 からはMI活用の成果 が多く報告されており 、MIは期待に応えられるということが共通理解になりつつあります。 MIとは？有効なものなのか？が大勢を占めていた数年前とは隔世の感があります。  本書を手に取っていただいた方は、 材料開発者として、 あるいは材料開発を支援する データ分析者として「MIを\n",
      "\n",
      "回答: \n",
      "\n",
      "MI（Materials Informatics）は、**材料の特性や性能を理解し、設計・開発を効率化するための、材料科学とデータ分析の融合**です。\n",
      "\n",
      "**具体的には、以下の要素が含まれます:**\n",
      "\n",
      "* **材料のデータベース:**  膨大な材料データの蓄積と管理\n",
      "* **データ分析:**  材料データから、材料の特性や性能を分析\n",
      "* **AI・機械学習:**  材料の設計・開発を支援するAIや機械学習モデルの開発\n",
      "* **シミュレーション:**  材料の性能を予測するためのシミュレーション\n",
      "\n",
      "**MIのメリット:**\n",
      "\n",
      "* **材料開発の効率化:**  従来の材料開発プロセスを大幅に短縮\n",
      "* **新しい材料の発見:**  膨大なデータから、新しい材料の発見が可能\n",
      "* **材料性能の向上:**  材料の性能をより正確に予測・設計\n",
      "* **コスト削減:**  材料開発コストを削減\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bf43ce230c405a9a823ffb359f192a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "質問: MIとは何ですか？\n",
       "\n",
       "関連情報: はじめに   良い材料を 早く創りたいので 、マテリアルズ・インフォマティクス（ MI）を活用して”いる”。このような声 はもう珍しくありません 。 MIブームに端を発して 、大学・企業 ともにMIの活用検討が 始められて 既にある程度の期間が 経過しました 。すでにMIに取り組んでいる 大学・企業 からはMI活用の成果 が多く報告されており 、MIは期待に応えられるということが共通理解になりつつあります。 MIとは？有効なものなのか？が大勢を占めていた数年前とは隔世の感があります。  本書を手に取っていただいた方は、 材料開発者として、 あるいは材料開発を支援する データ分析者として「MIを\n",
       "\n",
       "回答: \n",
       "\n",
       "MI（Materials Informatics）は、**材料の特性や性能を理解し、設計・開発を効率化するための、材料科学とデータ分析の融合**です。\n",
       "\n",
       "**具体的には、以下の要素が含まれます:**\n",
       "\n",
       "* **材料のデータベース:**  膨大な材料データの蓄積と管理\n",
       "* **データ分析:**  材料データから、材料の特性や性能を分析\n",
       "* **AI・機械学習:**  材料の設計・開発を支援するAIや機械学習モデルの開発\n",
       "* **シミュレーション:**  材料の性能を予測するためのシミュレーション\n",
       "\n",
       "**MIのメリット:**\n",
       "\n",
       "* **材料開発の効率化:**  従来の材料開発プロセスを大幅に短縮\n",
       "* **新しい材料の発見:**  膨大なデータから、新しい材料の発見が可能\n",
       "* **材料性能の向上:**  材料の性能をより正確に予測・設計\n",
       "* **コスト削減:**  材料開発コストを削減"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(ask_question(question)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
